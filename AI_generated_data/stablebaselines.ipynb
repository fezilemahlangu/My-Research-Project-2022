{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accept/reject our fourth hypothesis, we will collect AI generated data and compare the performance to human generated data. \n",
    "\n",
    "References:\n",
    "[Hill et al. 2018] Ashley Hill, Antonin Raffin, Maximilian Ernestus, Adam Gleave, Anssi\n",
    "Kanervisto, Rene Traore, Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex\n",
    "Nichol, Matthias Plappert, Alec Radford, John Schulman, Szymon Sidor, and\n",
    "Yuhuai Wu. Stable Baselines. https://github.com/hill-a/stable-baselines,\n",
    "2018.\n",
    "\n",
    "\n",
    "https://stable-baselines.readthedocs.io/en/master/guide/examples.html\n",
    "\n",
    "(this is ran in colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "# Create environment\n",
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "# Instantiate the agent\n",
    "model = DQN('MlpPolicy', env, learning_rate=1e-3, prioritized_replay=True, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(2e5))\n",
    "# Save the agent\n",
    "model.save(\"dqn_lunar\")\n",
    "del model  # delete trained model to demonstrate loading\n",
    "\n",
    "# Load the trained agent\n",
    "model = DQN.load(\"dqn_lunar\")\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "\n",
    "# Enjoy trained agent\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
