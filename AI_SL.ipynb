{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1STb4bJNDeMz2caxAjR0DNVSW9vVFpowy",
      "authorship_tag": "ABX9TyPYtenwaJe2f4Fg3IZKA+KT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fezilemahlangu/My-Research-Project-2022/blob/main/AI_SL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zipfile_deflate64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikft1PKdDDjF",
        "outputId": "da9d9090-c3f0-4475-84c3-ac7fe3e29496"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting zipfile_deflate64\n",
            "  Downloading zipfile_deflate64-0.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: zipfile-deflate64\n",
            "Successfully installed zipfile-deflate64-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uwgsZ0YGC0OU"
      },
      "outputs": [],
      "source": [
        "import zipfile_deflate64 as zipfile \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from io import BytesIO\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import time \n",
        "import csv \n",
        "\n",
        "from PIL import Image, ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_x(zipfiles,n_s):\n",
        "    '''\n",
        "    Function that opens a zipfile of images and returns an array of images. \n",
        "    The function also reduces the resolution of the images \n",
        "\n",
        "    @Args:\n",
        "        zfile: zipfile that contains images \n",
        "\n",
        "        n: number of images in the zipfile \n",
        "\n",
        "        deleted_rows: the images whose information have been deleted through cleaning \n",
        "\n",
        "    @returns:\n",
        "        training_X: array of images in the zip file \n",
        "    '''\n",
        "\n",
        "    training_X=[] \n",
        "\n",
        "    for i in range(len(zipfiles)):\n",
        "\n",
        "      archive = zipfile.Zipfile(zipfiles[i],'r')\n",
        "      n= n_s[i]\n",
        "\n",
        "      for i in range(n): #scan through zip file \n",
        "        \n",
        "        filename= BytesIO(archive.read(archive.namelist()[i])) #access an image in the zip file \n",
        "        image = PIL.Image.open(filename) #open colour image\n",
        "\n",
        "        #-------reducing the size/resolution of the image------#\n",
        "        # width = int(image.size[0] * scale_percent / 100)\n",
        "        # height = int(image.size[1] * scale_percent / 100)\n",
        "        width = 84\n",
        "        height = 84\n",
        "        dim = (width, height)\n",
        "        image = ImageOps.grayscale(image) #grayscale \n",
        "        # image = image.resize(dim,PIL.Image.ANTIALIAS)\n",
        "\n",
        "        #-----converting image to array and appending to training_X-----#\n",
        "        image=np.array(image) #convert image to array\n",
        "        image = image[:,:,None] #(84,84,1) \n",
        "        training_X.append(image/255.0) #-> normalized \n",
        "\n",
        "    return training_X\n"
      ],
      "metadata": {
        "id": "9IX00XHuDJzM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_y(df_s):\n",
        "    '''\n",
        "    This function returns the action column/attribute from the dataframe\n",
        "    These are the y values \n",
        "\n",
        "    @Args:\n",
        "        df: dataframe containing trial information \n",
        "    @returns:\n",
        "        an array of y values. Actions values taken with image \n",
        "    '''\n",
        "    actions = []\n",
        "    for df in df_s:\n",
        "      array = df.to_records(index=False)\n",
        "      for i in array:\n",
        "        actions.append(i[0])\n",
        "      # actions.append(i for i in array['1'])\n",
        "    \n",
        "    return actions\n",
        "\n",
        "    # array = df.to_records(index=False)\n",
        "    # return array['1']"
      ],
      "metadata": {
        "id": "-pxAZO7pDUhf"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model_config(train_x,train_y,val_x,val_y,test_x,test_y,img_shape,num_classes,first_layer, sec_layer,third_layer,fieldnames_results, fieldnames_model):\n",
        "    '''\n",
        "    This function takes in the hyperparameters of the model, builds and runs it.\n",
        "    It also saves the model hyperparameters and results from training and test scores \n",
        "    \n",
        "    @Args: \n",
        "        train_x: x values of the training data set \n",
        "        train_y: y values of the training data set \n",
        "        val_x: x values of the validation data set \n",
        "        val_y: y values of the validation data set \n",
        "        test_x: x values of the testing data set \n",
        "        test_y: y values of the testing data set \n",
        "        img_shape: the shape of the images; 3 by 3\n",
        "        num_classes: number of actions a player can make \n",
        "        first_layer: the hyperparameters of the first layer of the CNN\n",
        "        second_layer: the hyperparameters of the second layer of the CNN\n",
        "        fieldnames_results: field names of results.csv\n",
        "        fieldnames_models: field names of models.csv\n",
        "\n",
        "\n",
        "    @returns: Nothing \n",
        "    '''\n",
        "    #building model \n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(filters=first_layer[0],kernel_size=first_layer[1],strides=first_layer[2], padding=first_layer[3],activation=first_layer[4],input_shape=img_shape))\n",
        "    model.add(MaxPooling2D(pool_size=first_layer[5]))\n",
        "    model.add(Dropout(rate=first_layer[6]))\n",
        "    if(len(sec_layer)>1):\n",
        "        model.add(Conv2D(filters=sec_layer[0],kernel_size=sec_layer[1],strides=sec_layer[2],padding=sec_layer[3],activation=sec_layer[4]))\n",
        "        model.add(MaxPooling2D(pool_size=sec_layer[5]))\n",
        "        model.add(Dropout(rate=sec_layer[6]))\n",
        "    \n",
        "    if(len(third_layer)>1):\n",
        "        model.add(Conv2D(filters=third_layer[0],kernel_size=third_layer[1],strides=third_layer[2],padding=third_layer[3],activation=third_layer[4]))\n",
        "        model.add(MaxPooling2D(pool_size=third_layer[5]))\n",
        "        model.add(Dropout(rate=third_layer[6]))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=first_layer[7], activation = 'relu'))\n",
        "    model.add(Dropout(rate=first_layer[8]))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    #compile model\n",
        "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=first_layer[9]),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "    #early stopping \n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0.00001, patience = 3)\n",
        "\n",
        "    #run model \n",
        "    time_callback = timing_Callback() \n",
        "    start = time.time()\n",
        "    Atari_Conf_History =  model.fit(train_x, train_y, epochs = 25, validation_data=(val_x, val_y), callbacks=[time_callback,early_stopping])\n",
        "    total_time = time.time()-start \n",
        "\n",
        "    #save model hyperparameters to csv\n",
        "    save_model(fieldnames_model,first_layer,sec_layer,third_layer)\n",
        "\n",
        "    #save results to csv\n",
        "    # history = Atari_Conf_History.history \n",
        "    test_loss, test_acc = model.evaluate(test_x, test_y)\n",
        "    save_results(fieldnames_results,total_time,time_callback,test_acc,test_loss)\n",
        "\n",
        "    return  "
      ],
      "metadata": {
        "id": "qjac5g87DWFG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(trial):\n",
        "\n",
        "    game_folder= str(\"/content/drive/MyDrive/AI_atari_data/enduro/\")\n",
        "\n",
        "    zipname=game_folder+\"trial\"+str(trial)+\".zip\"\n",
        "    # textfile=game_folder+str(trial)+\".txt\"\n",
        "    csv=game_folder+\"actions_trial\"+str(trial)+\".csv\"\n",
        "\n",
        "    # read_file=pd.read_csv(textfile)\n",
        "    # read_file.to_csv(csv,index=True)\n",
        "    df= pd.read_csv(csv)\n",
        "\n",
        "    return zipname, df "
      ],
      "metadata": {
        "id": "WFTH2aA0DaNF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zipfiles=[]\n",
        "n_s=[]\n",
        "df_s=[]\n",
        "\n",
        "trial = 1\n",
        "zipname,df= get_data(trial) #trial =1\n",
        "n=len(df) #number of frames in trial\n",
        "zipfiles.append(zipname)\n",
        "n_s.append(n)\n",
        "df_s.append(df)\n",
        "\n",
        "# create_train_y(df).shape\n",
        "\n",
        "trial = 2 #trial 2\n",
        "zipname,df= get_data(trial)\n",
        "n=len(df)\n",
        "zipfiles.append(zipname)\n",
        "n_s.append(n)\n",
        "df_s.append(df)\n",
        "\n",
        "trial = 3 #trial 3\n",
        "zipname,df= get_data(trial)\n",
        "n=len(df)\n",
        "zipfiles.append(zipname)\n",
        "n_s.append(n)\n",
        "df_s.append(df)\n",
        "\n",
        "#----------------------------------#\n",
        "images = create_train_x(zipfiles,n_s)\n",
        "actions = create_train_y(df_s)\n"
      ],
      "metadata": {
        "id": "3njf9F0SegBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import csv \n",
        "\n",
        "#-----------------------------------------------------------------#\n",
        "#prepare csv for results \n",
        "# fieldnames_results = ['total_time', 'call_back_time','test_acc','test_loss'] \n",
        "# with open('/home-mscluster/fmahlangu/2089676/atari_enduro_data/results.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "#     writer = csv.DictWriter(f, fieldnames=fieldnames_results)\n",
        "#     writer.writeheader()\n",
        "\n",
        "# #prepare csv for results \n",
        "# fieldnames_m = ['first_layer','second_layer','third_layer'] \n",
        "# with open('/home-mscluster/fmahlangu/2089676/atari_enduro_data/models.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "#     writer = csv.DictWriter(f, fieldnames=fieldnames_m)\n",
        "#     writer.writeheader()\n",
        "\n",
        "#-----------retrieving training data----------------------------#\n",
        "#TO DO: change to function \n",
        "'''\n",
        "Extracting data for training \n",
        "\n",
        "Meta_data.csv contains:\n",
        "trial_id used to locate the associated .tar.bz2 file and label file \n",
        "total_frame: number of image frame in .bar.b2 repository \n",
        "\n",
        "'''\n",
        "\n",
        "# metaData_df= pd.read_csv('/home-mscluster/fmahlangu/2089676/atari_enduro_data/meta_data.csv')\n",
        "\n",
        "# dataframe= metaData_df[metaData_df.GameName==\"enduro\"]\n",
        "\n",
        "#-------------------------------------------------------trial = 441 -------------------------------------------------------\n",
        "trial = 2\n",
        "zipname,df= get_data(trial) #trial =441\n",
        "\n",
        "\n",
        "#get images with associated actions for each trial \n",
        "n=len(df) #number of frames in trial\n",
        "\n",
        "\n",
        "# print(df)\n",
        "# create_train_y(df).shape\n",
        "\n",
        "df_s=[]\n",
        "\n",
        "df_s.append(df)\n",
        "df_s.append(df)\n",
        "\n",
        "len(create_train_y(df_s))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# images = create_train_x(zipname,n)\n",
        "# n=dataframe[dataframe.trial_id==trial].total_frame.tolist() #get number of frame/images\n",
        "# n=n[0]\n",
        "\n",
        "# df,deleted_rows=clean_df(df)\n",
        "# images=create_train_x(zipname,n,deleted_rows)\n",
        "# actions=create_train_y(df)\n",
        "\n",
        "# trainX, valX, trainY, valY = train_test_split(images, actions, test_size=0.18)\n",
        "# trainX, testX, trainY, testY = train_test_split(trainX, trainY, test_size=0.12)\n",
        "\n",
        "# #-----------#\n",
        "# trainX = np.array(trainX)\n",
        "# valX = np.array(valX)\n",
        "# testX = np.array(testX)\n",
        "\n",
        "# trainY = np.array(trainY)\n",
        "# valY = np.array(valY)\n",
        "# testY = np.array(testY)\n",
        "\n",
        "\n",
        "# # #-------------------------------------------------------trial = 103 -------------------------------------------------------\n",
        "# trial= 103\n",
        "# zipname,df= get_data(trial)\n",
        "\n",
        "# #get images with associated actions for each trial \n",
        "# n=dataframe[dataframe.trial_id==trial].total_frame.tolist() #get number of frame/images\n",
        "# n=n[0]\n",
        "\n",
        "# df,deleted_rows=clean_df(df)\n",
        "# images=create_train_x(zipname,n,deleted_rows)\n",
        "# actions=create_train_y(df)\n",
        "\n",
        "# trainX1, valX1, trainY1, valY1 = train_test_split(images, actions, test_size=0.18)\n",
        "# trainX1, testX1, trainY1, testY1 = train_test_split(trainX1, trainY1, test_size=0.12)\n",
        "\n",
        "# trainX1 = np.array(trainX1)\n",
        "# valX1 = np.array(valX1)\n",
        "# testX1 = np.array(testX1)\n",
        "# trainY1 = np.array(trainY1)\n",
        "# valY1 = np.array(valY1)\n",
        "# testY1 = np.array(testY1)\n",
        "\n",
        "# # #-------------------------------------------------------trial = 113 -------------------------------------------------------\n",
        "# trial= 113\n",
        "# zipname,df= get_data(trial)\n",
        "\n",
        "# #get images with associated actions for each trial \n",
        "# n=dataframe[dataframe.trial_id==trial].total_frame.tolist() #get number of frame/images\n",
        "# n=n[0]\n",
        "\n",
        "# df,deleted_rows=clean_df(df)\n",
        "# images=create_train_x(zipname,n,deleted_rows)\n",
        "# actions=create_train_y(df)\n",
        "\n",
        "# trainX2, valX2, trainY2, valY2 = train_test_split(images, actions, test_size=0.18)\n",
        "# trainX2, testX2, trainY2, testY2 = train_test_split(trainX2, trainY2, test_size=0.12)\n",
        "\n",
        "# trainX2 = np.array(trainX2)\n",
        "# valX2 = np.array(valX2)\n",
        "# testX2 = np.array(testX2)\n",
        "# trainY2 = np.array(trainY2)\n",
        "# valY2 = np.array(valY2)\n",
        "# testY2 = np.array(testY2)\n",
        "\n",
        "\n",
        "# alltrainX = []\n",
        "\n",
        "# for i in range(trainX.shape[0]):\n",
        "#   alltrainX.append(trainX[i])\n",
        "\n",
        "# for i in range(trainX1.shape[0]):\n",
        "#   alltrainX.append(trainX1[i])\n",
        "\n",
        "# for i in range(trainX2.shape[0]):\n",
        "#   alltrainX.append(trainX2[i])\n",
        "\n",
        "# alltrainX = np.array(alltrainX)\n",
        "\n",
        "# alltrainY = []\n",
        "\n",
        "# for i in range(trainY.shape[0]):\n",
        "#   alltrainY.append(trainY[i])\n",
        "\n",
        "# for i in range(trainY1.shape[0]):\n",
        "#   alltrainY.append(trainY1[i])\n",
        "\n",
        "# for i in range(trainY2.shape[0]):\n",
        "#   alltrainY.append(trainY2[i])\n",
        "\n",
        "# alltrainY = np.array(alltrainY)\n",
        "\n",
        "# alltestX = []\n",
        "\n",
        "# for i in range(testX.shape[0]):\n",
        "#   alltestX.append(testX[i])\n",
        "\n",
        "# for i in range(testX1.shape[0]):\n",
        "#   alltestX.append(testX1[i])\n",
        "\n",
        "# for i in range(testX2.shape[0]):\n",
        "#   alltestX.append(testX2[i])\n",
        "\n",
        "# alltestX = np.array(alltestX)\n",
        "\n",
        "# alltestY = []\n",
        "\n",
        "# for i in range(testY.shape[0]):\n",
        "#   alltestY.append(testY[i])\n",
        "\n",
        "# for i in range(testY1.shape[0]):\n",
        "#   alltestY.append(testY1[i])\n",
        "\n",
        "# for i in range(testY2.shape[0]):\n",
        "#   alltestY.append(testY2[i])\n",
        "\n",
        "# alltestY = np.array(alltestY)\n",
        "\n",
        "# allvalX = []\n",
        "\n",
        "# for i in range(valX.shape[0]):\n",
        "#   allvalX.append(valX[i])\n",
        "\n",
        "# for i in range(valX1.shape[0]):\n",
        "#   allvalX.append(valX1[i])\n",
        "\n",
        "# for i in range(valX2.shape[0]):\n",
        "#   allvalX.append(valX2[i])\n",
        "\n",
        "# allvalX = np.array(allvalX)\n",
        "\n",
        "# allvalY = []\n",
        "\n",
        "# for i in range(valY.shape[0]):\n",
        "#   allvalY.append(valY[i])\n",
        "\n",
        "# for i in range(valY1.shape[0]):\n",
        "#   allvalY.append(valY1[i])\n",
        "\n",
        "# for i in range(valY2.shape[0]):\n",
        "#   allvalY.append(valY2[i])\n",
        "\n",
        "# allvalY = np.array(allvalY)\n",
        "\n",
        "# #---------converting y values to categorical data (one-hot encoding)---#\n",
        "# # img_shape = [109, 83, 3]\n",
        "# img_shape = [84, 84, 1]\n",
        "# num_classes = 18\n",
        "\n",
        "# alltrainY = keras.utils.to_categorical(alltrainY, num_classes)\n",
        "# allvalY = keras.utils.to_categorical(allvalY, num_classes)\n",
        "# alltestY = keras.utils.to_categorical(alltestY, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS4EH-hEDgpI",
        "outputId": "2ef31169-9037-4502-895b-68852cc429cf"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13298"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    }
  ]
}